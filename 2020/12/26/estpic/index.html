<!DOCTYPE html>
<html lang="en">

<head>

  <!-- Minima -->
  <!-- Hexo theme created by @adisaktijrs -->

  <!-- Basic Page Needs
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta charset="utf-8">

  
  <title>【BIT AI大作业】五子棋博弈 (一）位置识别</title>
  
  <link rel="canonical" href="http://youwebsit.com/2020/12/26/estpic/">
  
  <meta name="description" content="实验要求采用人工智能方法解决五子棋博弈问题，要求如下：  能够用拍照方式识别五子棋下棋过程中当前落子的位置，识别程序中应使用到监督学习算法。 采用一种博弈搜索算法，实现五子棋博弈程序，其中对棋局状态的判断采用人为设定函数方式。 将上述博弈搜索算法中判断棋局状态的函数改为一种人工神经网络模型，并采用进">
  
  
  <meta name="author" content="John Doe">
  
  <meta property="og:image" content="http://youwebsit.comundefined">
  
  <meta property="og:site_name" content="Hexo" />
  <meta property="og:type" content="article" />
  <meta property="og:title" content="【BIT AI大作业】五子棋博弈 (一）位置识别" />
  
  <meta property="og:description" content="实验要求采用人工智能方法解决五子棋博弈问题，要求如下：  能够用拍照方式识别五子棋下棋过程中当前落子的位置，识别程序中应使用到监督学习算法。 采用一种博弈搜索算法，实现五子棋博弈程序，其中对棋局状态的判断采用人为设定函数方式。 将上述博弈搜索算法中判断棋局状态的函数改为一种人工神经网络模型，并采用进">
  
  <meta property="og:url" content="http://youwebsit.com/2020/12/26/estpic/" />

  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="【BIT AI大作业】五子棋博弈 (一）位置识别">
  
  <meta name="twitter:description" content="实验要求采用人工智能方法解决五子棋博弈问题，要求如下：  能够用拍照方式识别五子棋下棋过程中当前落子的位置，识别程序中应使用到监督学习算法。 采用一种博弈搜索算法，实现五子棋博弈程序，其中对棋局状态的判断采用人为设定函数方式。 将上述博弈搜索算法中判断棋局状态的函数改为一种人工神经网络模型，并采用进">
  
  
  <meta name="twitter:image" content="http://youwebsit.comundefined">
  
  <meta name="twitter:url" content="http://youwebsit.com/2020/12/26/estpic/" />

  <!-- Mobile Specific Metas
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- Preload fonts
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="preload" href="../fonts/dm-serif-display-v4-latin-regular.woff2" as="font" type="font/woff2" crossorigin>
  <link rel="preload" href="../fonts/inter-v2-latin-regular.woff2" as="font" type="font/woff2" crossorigin>

  <!-- CSS
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  
<link rel="stylesheet" href="/css/normalize.css">

  
<link rel="stylesheet" href="/css/skeleton.css">

  
<link rel="stylesheet" href="/css/custom.css">

  
<link rel="stylesheet" href="/css/prism-dark.css">

  
<link rel="stylesheet" href="/css/prism-line-numbers.css">

  <!-- User css -->
  
  
<link rel="stylesheet" href="/css/user.css">

  

  <!-- Favicon
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="icon" type="image/png" href="/images/favicon.png">

  <!-- Custom Theme Color Style
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <style>
  a:not(.icon) {
    text-decoration-color: #0FA0CE;
    background-image: linear-gradient(
      to bottom,
      rgba(0, 0, 0, 0) 50%,
      #0FA0CE 50%
    );
  }
  blockquote {
    border-left: 8px solid #0FA0CE;
  }
  .nanobar .bar {
    background: #0FA0CE;
  }
  .button.button-primary:hover,
  button.button-primary:hover,
  input[type="submit"].button-primary:hover,
  input[type="reset"].button-primary:hover,
  input[type="button"].button-primary:hover,
  .button.button-primary:focus,
  button.button-primary:focus,
  input[type="submit"].button-primary:focus,
  input[type="reset"].button-primary:focus,
  input[type="button"].button-primary:focus {
    background-color: #0FA0CE;
    border-color: #0FA0CE;
  }
  input[type="email"]:focus,
  input[type="number"]:focus,
  input[type="search"]:focus,
  input[type="text"]:focus,
  input[type="tel"]:focus,
  input[type="url"]:focus,
  input[type="password"]:focus,
  textarea:focus,
  select:focus {
    border: 1px solid #0FA0CE;
  }
</style>

  <!-- Google Analytics (With Privacy Settings On)
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  

<meta name="generator" content="Hexo 5.3.0"></head>

<body>
  <div class="container">
    <div class="row">
      <div>

        <div class="row">
  <div class="two columns" style="max-width: 50px">
    <h1 class="mt-2 mode">
      <div onclick=setDarkMode(true) id="darkBtn">🌑</div>
      <div onclick=setDarkMode(false) id="lightBtn" class=hidden>☀️</div>
      <script >
        if (localStorage.getItem('preferredTheme') == 'dark') {
          setDarkMode(true)
        }
        function setDarkMode(isDark) {
          var darkBtn = document.getElementById('darkBtn')
          var lightBtn = document.getElementById('lightBtn')
          if (isDark) {
            lightBtn.style.display = "block"
            darkBtn.style.display = "none"
            localStorage.setItem('preferredTheme', 'dark');
          } else {
            lightBtn.style.display = "none"
            darkBtn.style.display = "block"
            localStorage.removeItem('preferredTheme');
          }
          document.body.classList.toggle("darkmode");
        }
      </script>
    </h1>
  </div>

  <div class="six columns ml-1">
    <h1 class="mt-2">
      Hi Folks.
    </h1>
  </div>

  <div class="twelve columns">
    <div class="row">
      <div class="nine columns left">
        <a href="/">Home</a>
        
          
          <a href="/Works" class="ml">Works</a>
          
        
          
          <a href="/About" class="ml">About</a>
          
        
        
          
            <a href="mailto:test@test.test" target="_blank" class="ml">Email</a>
          
        
      </div>
    </div>
    <hr style="margin-bottom: 2.6rem">
  </div>
</div>

        <div class="trans">
            <h2>【BIT AI大作业】五子棋博弈 (一）位置识别</h2>

  <h2 id="实验要求"><a href="#实验要求" class="headerlink" title="实验要求"></a><a href="">实验要求</a></h2><p>采用人工智能方法解决五子棋博弈问题，要求如下：</p>
<ul>
<li><strong>能够用拍照方式识别五子棋下棋过程中当前落子的位置，识别程序中应使用到监督学习算法。</strong></li>
<li>采用一种博弈搜索算法，实现五子棋博弈程序，其中对棋局状态的判断采用人为设定函数方式。</li>
<li>将上述博弈搜索算法中判断棋局状态的函数改为一种人工神经网络模型，并采用进化计算方法对该人工神经网络模型来进行学习，使得五子棋博弈程序的下棋水平不断提高。 </li>
<li>采用强化学习算法对上述人工神经网络模型进行学习，使得五子棋博弈程序的下棋水平不断提高。 </li>
</ul>
<h2 id="实验流程"><a href="#实验流程" class="headerlink" title="实验流程"></a><a href="">实验流程</a></h2><p>为便于收集训练数据，我是按照2、4、3、1的顺序完成作业的，下面对我实验的大致流程进行介绍。</p>
<p>首先我设定了一个类Gobang，在这个类中设定棋局逻辑，然后设定一个继承他的类GobangPlay，在该类中调用pygame相关函数绘制前端，使AI训练下棋的过程可以动态观测。</p>
<p>接着，我写了一个基于博弈搜索算法的AI，使其采用极大极小搜索的算法搜索当前的棋盘可落子的每一个位置，并找出假设对手采取最佳策略的情况下，对于当前顺序的玩家最优的落子位置。这里我运用alpha-beta剪枝、限制搜索半径、棋子估值等一系列提速操作。搜索叶节点的值采用棋盘估值函数的方式。我将棋形分为连五、活四、冲四、活三、眠三、活二、眠二七种棋形，并分别为其设定合适的分数。用己方棋形分数之和减去敌方棋形分数和，即得到当前棋局的分数。</p>
<p>接着，我将博弈搜索中的棋盘估值函数改为一个CNN网络，并用强化学习中DQN的方法互博学习。</p>
<p>训练好强化学习后，我用numpy手写了一个新的ANN网络替代博弈搜索中的估值函数，并采用进化算法进行监督训练。对于数据集，我保存强化学习和博弈树对弈过程中博弈数极大极小搜索过程中的棋盘保存一万两千份作为训练样本，同时保存其人为设定函数返回的棋面分数并用tanh处理得到训练标签。取适应度为ANN的输出值与标签的欧氏距离作为适应度进行进化训练。</p>
<p>最后对第一问进行实现。我采用resnet18网络结构，输入图片，输出棋盘列表。设定阈值后，根据列表中每一位对应的值判断该位置是黑棋、白棋还是空位。我调用pygame中的函数将强化学习互博中的棋盘截屏2万张作为第一问的训练数据，并保存对应的棋盘列表作为第一问的训练标签。经过100轮训练后发现损失函数完全收敛，再次从强化学习互博中抽取10张图片使用网络预测并进行标定截图，目标检测的准确率高达100%。</p>
<p>接下来，我将详细介绍每一个作业的具体实现方式。</p>
<h4 id="1-构造数据集"><a href="#1-构造数据集" class="headerlink" title="1.构造数据集"></a><a href="">1.构造数据集</a></h4><p>如实验流程所说，实验一的训练数据来源于强化学习互博中的屏幕截图，而标签是对应的棋盘列表。棋盘列表是指在整个下棋过程中维护的一个标识棋盘位置的数据结构，是一个大小为15*15的列表。每一个值对应棋盘上一个位置上是黑子、白子还是空。在这里，我设置黑子为1，白子为-1，空为0。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Narumi-Maria/CDN/images/pasted-10.png" alt="upload successful"></p>
<p>对于第一问，我构造了20000个训练样本和对应的标签，图片存放screnn文件夹中，名字为编号.jpg，标签为pos.pkl。</p>
<p><img src="https://cdn.jsdelivr.net/gh/Narumi-Maria/CDN/images/pasted-11.png" alt="upload successful"></p>
<h4 id="2-搭建神经网络"><a href="#2-搭建神经网络" class="headerlink" title="2.搭建神经网络"></a><a href="">2.搭建神经网络</a></h4><p>一开始我尝试自己搭建了一个四层的ANN网络，但是训练效果并不理想。损失函数无法收敛。故此我采用了resnet18作为网络的骨架，再加上一个线性层得到想要的输出维度，得到了不错的训练效果。</p>
<p>首先简要介绍一下resnet18。我们都知道，增加网络层数可以拟合更复杂的函数，进行更加复杂的特征模式的提取。但是由于深层网络存在着梯度消失或者爆炸的问题，这使得深度学习模型很难训练。而深度残差网络（Deep residual network, ResNet）的提出便是为了解决这一问题。</p>
<p>Resnet的核心思想是：对于一个堆积层结构（几层堆积而成），当输入为x时，其学习到的特征记为H(x)。现在我们希望其可以学习到残差F(x)=H(x)-x，这样其实原始的学习特征是x+F(x)。这样当残差接近0时，此时堆积近似做了恒等映射，至少网络性能不会下降。</p>
<p>而Resnet即是由多个残差块堆叠而成的网络，如下图所示：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Narumi-Maria/CDN/images/pasted-13.png" alt="upload successful"></p>
<p>这一问中我搭建的神经网络的主要工作原理是：输入一个batchsize<em>3</em>256<em>256的图片（我调试发现pytorch中的Resnet18支持多种维度的输入，这里我选择了256），输出一个batchsize</em>225维的tensor。之后我们只需要把这225维转化成15*15维，并根据每一维的值与预设阈值之间的关系，就可以判断该位置是黑子、白子还是空位了。这里我设置的阈值如下：</p>
<ul>
<li>predict_pos[j][x][y] &lt; -0.5：白</li>
<li>predict_pos[j][x][y] &gt; 0.5：黑</li>
<li>-0.5 &lt;= predict_pos[j][x][y] &lt;= 0.5：空位</li>
</ul>
<h4 id="3-初始化训练"><a href="#3-初始化训练" class="headerlink" title="3.初始化训练"></a><a href="">3.初始化训练</a></h4><p>首先把pos.pkl加载出来，得到一个标识棋盘状态的（训练样本数20000，15，15）的列表。我将其reshape为（20000，225）的维度，便于其与网络输出进行损失函数的计算。</p>
<p>接着我使用自定义的类Image Dataset来处理训练数据，得到捆绑好的训练数据data。Image Dataset继承自torch.utils.data中的Dataset类，用于自定义加载数据。它的主要功能如下：</p>
<ul>
<li>将训练图片打开，将其长、宽从520转为256。接着用转为[3,256,256]维的tensor。（RGB图片通道数为3）。</li>
<li>将训练图片与对应的标签绑定，其中标签来自刚刚处理pos.pkl得到得张量。</li>
</ul>
<p>接着调用torch.utils.data中得DataLoader函数为训练数据分批并打乱。这里我设置batchsize的大小为128。</p>
<p>由于网络输出与标签的维度相同，且我们希望网络输出尽可能地接近标签。所以这里我采用均方误差函数MSELoss评价网络输出与期望值之间的差距，并且为了提高实验精度，我将其取平均的操作改为求和操作（设置reduction=’sum’），其公式如下：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Narumi-Maria/CDN/images/pasted-14.png" alt="upload successful"><br>采用Adam优化器对网络参数进行优化，并将网络、评价器、优化器都放在GPU上进行加速。</p>
<h4 id="4-训练"><a href="#4-训练" class="headerlink" title="4.训练"></a><a href="">4.训练</a></h4><p>每轮训练的过程大致如下：</p>
<ul>
<li>将分好批的训练数据放入GPU上加速</li>
<li>将每批图片输入到网络之中得到预测值</li>
<li>计算预测值与标签的损失函数</li>
<li>采用pytorch的自动求导功能进行优化。</li>
</ul>
<h4 id="5-代码"><a href="#5-代码" class="headerlink" title="5.代码"></a><a href="">5.代码</a></h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;监督学习，拍照识别落子位置&#x27;</span><span class="string">&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line">from PIL import Image</span><br><span class="line">import torch</span><br><span class="line">from torch.utils.data import Dataset, DataLoader</span><br><span class="line">from torchvision import transforms</span><br><span class="line">from torchvision.models import resnet18</span><br><span class="line">import torch.nn as nn</span><br><span class="line">import torch.optim as optim</span><br><span class="line">import pickle</span><br><span class="line">import pygame</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">ONLYTEST = <span class="string">&quot;True&quot;</span>  <span class="comment"># 是否只检测不训练</span></span><br><span class="line">CONTINUE = <span class="string">&quot;False&quot;</span>  <span class="comment"># 是否继续训练</span></span><br><span class="line">WEIGHTPATH = <span class="string">&quot;weight/task1_resnet18_weight.pkl&quot;</span>  <span class="comment"># 权重地址</span></span><br><span class="line">DEVICE = <span class="string">&quot;cuda&quot;</span>  <span class="comment"># 使用GPU加速</span></span><br><span class="line">SCREENPATH = <span class="string">&quot;Data/task1_screen/&quot;</span>  <span class="comment"># 训练集地址</span></span><br><span class="line">LABELPATH = <span class="string">&quot;Data/task1_pos.pkl&quot;</span>  <span class="comment"># 训练标签地址</span></span><br><span class="line">TEST_SCREENPATH = <span class="string">&quot;Data/task1_screen_test/test_&quot;</span>  <span class="comment"># 测试集地址</span></span><br><span class="line">TEST_RESULTPATH = <span class="string">&quot;Data/task1_screen_test_result/test_&quot;</span>  <span class="comment"># 测试结果地址</span></span><br><span class="line">NUM_TEST = 11  <span class="comment"># 测试集大小</span></span><br><span class="line">BATCHSIZE = 128  <span class="comment"># 分批大小</span></span><br><span class="line">LR = 0.00001  <span class="comment"># 学习率</span></span><br><span class="line">EPOCH = 1  <span class="comment"># 训练轮数</span></span><br><span class="line"></span><br><span class="line">PURPLE = (255, 0, 255)  <span class="comment"># 紫色用来标记白色棋子的位置</span></span><br><span class="line">YELLOW = (255, 255, 0)  <span class="comment"># 黄色用来标记黑色棋子的位置</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用torchvision.models中的resnet18</span></span><br><span class="line">def get_resnet18():</span><br><span class="line">    net = resnet18()</span><br><span class="line">    modified_net = nn.Sequential(*list(net.children())[:-1])</span><br><span class="line">    <span class="built_in">return</span> modified_net</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 用于识别落子位置的网络，在renet18的骨架上加一个线性层来实现本次任务</span></span><br><span class="line"><span class="comment"># 输入为一个batch的图片，大小batchisize*3*256*256</span></span><br><span class="line"><span class="comment"># 输出为一个长度为225的tensor，每一位表示棋盘中一个位置</span></span><br><span class="line">class Location(nn.Module):</span><br><span class="line">    def __init__(self, inputsize=3 * 256 * 256, pos=15 * 15):</span><br><span class="line">        super(Location, self).__init__()</span><br><span class="line">        self.inputsize = inputsize</span><br><span class="line">        <span class="comment"># 这部分是我之前手写的ANN网络，效果不是很好，主要是用来对比resnet的强大的</span></span><br><span class="line">        <span class="comment"># self.l1 = torch.nn.Linear(inputsize, 512)</span></span><br><span class="line">        <span class="comment"># self.l2 = torch.nn.Linear(512, 256)</span></span><br><span class="line">        <span class="comment"># self.l3 = torch.nn.Linear(256, 128)</span></span><br><span class="line">        <span class="comment"># self.l4 = torch.nn.Linear(128, pos)</span></span><br><span class="line">        self.backbone = get_resnet18()</span><br><span class="line">        self.extra_layer = nn.Linear(512, pos)</span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        out = self.backbone(x)</span><br><span class="line">        out = torch.flatten(out, 1)</span><br><span class="line">        out = self.extra_layer(out)</span><br><span class="line">        <span class="built_in">return</span> out</span><br><span class="line">        <span class="comment"># x = x.view(-1, self.inputsize)</span></span><br><span class="line">        <span class="comment"># x = torch.tanh(self.l1(x))</span></span><br><span class="line">        <span class="comment"># x = torch.tanh(self.l2(x))</span></span><br><span class="line">        <span class="comment"># x = torch.tanh(self.l3(x))</span></span><br><span class="line">        <span class="comment"># return torch.tanh(self.l4(x))</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 处理训练数据</span></span><br><span class="line">class ImageDataset(Dataset):</span><br><span class="line">    def __init__(self, out):</span><br><span class="line">        super(ImageDataset, self).__init__()</span><br><span class="line">        self.location = out</span><br><span class="line">        self.transforms_ = transforms.Compose([</span><br><span class="line">            transforms.Resize(256),</span><br><span class="line">            transforms.ToTensor()</span><br><span class="line">        ])</span><br><span class="line"></span><br><span class="line">    def __len__(self):</span><br><span class="line">        <span class="built_in">return</span> len(self.location)</span><br><span class="line"></span><br><span class="line">    def __getitem__(self, item):</span><br><span class="line">        img = Image.open(SCREENPATH + str(item) + <span class="string">&quot;.jpg&quot;</span>)  <span class="comment"># 打开图片</span></span><br><span class="line">        img = self.transforms_(img)  <span class="comment"># 处理图片</span></span><br><span class="line">        label = self.location[item]</span><br><span class="line">        label = torch.tensor(label, dtype=torch.float32)</span><br><span class="line">        <span class="built_in">return</span> img, label</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="string">&#x27;&#x27;</span><span class="string">&#x27;初始化&#x27;</span><span class="string">&#x27;&#x27;</span></span><br><span class="line">    f = open(LABELPATH, <span class="string">&quot;rb&quot;</span>)</span><br><span class="line">    pos = pickle.load(f)  <span class="comment"># 加载图片的标签，大小：训练数据数*15*15</span></span><br><span class="line">    f.close()</span><br><span class="line">    <span class="comment"># 处理标签</span></span><br><span class="line">    pos = np.array(pos)</span><br><span class="line">    pos = pos.reshape(-1, 225)</span><br><span class="line">    <span class="comment"># 处理训练图片</span></span><br><span class="line">    data = ImageDataset(pos)</span><br><span class="line">    <span class="comment"># 数据分批</span></span><br><span class="line">    train_loader = DataLoader(data, batch_size=BATCHSIZE, shuffle=True)</span><br><span class="line">    <span class="comment"># 设置训练方案并将模型放在GPU加速</span></span><br><span class="line">    net = Location().to(DEVICE)</span><br><span class="line">    criterion = nn.MSELoss(reduction=<span class="string">&#x27;sum&#x27;</span>).to(DEVICE)  <span class="comment"># 损失函数计算方式</span></span><br><span class="line">    optimizer = optim.Adam(net.parameters(), lr=LR)  <span class="comment"># 优化器</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 训练</span></span><br><span class="line">    <span class="keyword">if</span> ONLYTEST == <span class="string">&quot;False&quot;</span>:</span><br><span class="line">        <span class="keyword">if</span> CONTINUE == <span class="string">&quot;True&quot;</span>:  <span class="comment"># 继续上次训练</span></span><br><span class="line">            net.load_state_dict(torch.load(WEIGHTPATH))</span><br><span class="line">        net.train()</span><br><span class="line">        Loss = 0</span><br><span class="line">        cost = []  <span class="comment"># 画图点</span></span><br><span class="line">        <span class="keyword">for</span> epoch <span class="keyword">in</span> range(EPOCH):</span><br><span class="line">            <span class="keyword">for</span> n_iter, (img, label) <span class="keyword">in</span> enumerate(train_loader):</span><br><span class="line">                img = img.to(DEVICE)</span><br><span class="line">                label = label.to(DEVICE)</span><br><span class="line">                optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">                predict_pos = net(img)  <span class="comment"># 前向传播</span></span><br><span class="line">                loss = criterion(predict_pos, label)  <span class="comment"># 求损失函数</span></span><br><span class="line"></span><br><span class="line">                loss.backward()  <span class="comment"># 自动求导</span></span><br><span class="line">                optimizer.step()  <span class="comment"># 优化更新网络参数</span></span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> n_iter == 1:  <span class="comment"># 打印每轮训练第一批的loss作图</span></span><br><span class="line">                    Loss = loss</span><br><span class="line">                    cost.append(Loss)</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;epoch: %d/%d batch:%d/%d loss: %.6f&quot;</span> % (epoch, EPOCH, n_iter, len(train_loader), loss.item()))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 保存权重</span></span><br><span class="line">        torch.save(net.state_dict(), WEIGHTPATH)</span><br><span class="line">        <span class="comment"># 画出损失函数下降曲线</span></span><br><span class="line">        costs = np.squeeze(cost)</span><br><span class="line">        plt.plot(costs)</span><br><span class="line">        plt.ylabel(<span class="string">&#x27;Loss&#x27;</span>)</span><br><span class="line">        plt.xlabel(<span class="string">&#x27;iterations (per 1)&#x27;</span>)</span><br><span class="line">        plt.title(<span class="string">&quot;(resnet18_with_LR=) : &quot;</span> + str(LR))</span><br><span class="line">        plt.show()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">else</span>: <span class="comment">#如果只检测不训练</span></span><br><span class="line">        net.load_state_dict(torch.load(WEIGHTPATH))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 检测预测效果</span></span><br><span class="line">    net = net.to(<span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">    net.eval()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(NUM_TEST):  <span class="comment"># 遍历测试集的每张图</span></span><br><span class="line">        pygame.init()</span><br><span class="line">        screen = pygame.display.set_mode((520, 520))</span><br><span class="line">        <span class="comment"># 打开测试集的第i张图片</span></span><br><span class="line">        screen.blit(pygame.image.load(TEST_SCREENPATH + str(i) + <span class="string">&quot;.jpg&quot;</span>), (0, 0))</span><br><span class="line">        img = Image.open(TEST_SCREENPATH + str(i) + <span class="string">&quot;.jpg&quot;</span>)</span><br><span class="line">        transforms_2 = transforms.Compose([</span><br><span class="line">            transforms.Resize(256),</span><br><span class="line">            transforms.ToTensor()</span><br><span class="line">        ])</span><br><span class="line">        img = transforms_2(img)</span><br><span class="line">        img = img.unsqueeze(0)</span><br><span class="line">        with torch.no_grad():</span><br><span class="line">            <span class="comment"># 得到图片的预测结果predict_pos</span></span><br><span class="line">            predict_pos = net(img)</span><br><span class="line">            predict_pos = predict_pos.numpy()</span><br><span class="line">            predict_pos = predict_pos.reshape(-1, 15, 15)</span><br><span class="line">            location_stak = []</span><br><span class="line">            <span class="comment"># 把predict_pos中的每一个位置还原为棋子信息并装入location_stak，&lt;-0.5为白棋，&gt;0.5为黑棋，否则为空</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(predict_pos.shape[0]):</span><br><span class="line">                <span class="keyword">for</span> x <span class="keyword">in</span> range(15):</span><br><span class="line">                    <span class="keyword">for</span> y <span class="keyword">in</span> range(15):</span><br><span class="line">                        <span class="keyword">if</span> predict_pos[j][x][y] &lt; -0.5:</span><br><span class="line">                            location_stak.append((-1, x, y))</span><br><span class="line">                        <span class="keyword">elif</span> predict_pos[j][x][y] &gt; 0.5:</span><br><span class="line">                            location_stak.append((1, x, y))</span><br><span class="line">            <span class="comment"># 把location_stak中的每颗棋子画出来，展示目标检测结果。预测为黑的位置画黄点，预测为白的位置画紫点</span></span><br><span class="line">            <span class="keyword">for</span> item <span class="keyword">in</span> location_stak:</span><br><span class="line">                x = 50 + item[1] * 30</span><br><span class="line">                y = 50 + item[2] * 30</span><br><span class="line">                mst_color = YELLOW <span class="keyword">if</span> item[0] == 1 <span class="keyword">else</span> PURPLE</span><br><span class="line">                pygame.draw.circle(screen, mst_color, [x, y], int(30 / 4))</span><br><span class="line">                pygame.display.update()</span><br><span class="line">            <span class="comment"># 将标记好识别位置的结果截屏保存</span></span><br><span class="line">            pygame.image.save(screen, TEST_RESULTPATH + str(i) + <span class="string">&quot;.jpg&quot;</span>)</span><br></pre></td></tr></table></figure>
<h4 id="6-实验结果"><a href="#6-实验结果" class="headerlink" title="6.实验结果"></a><a href="">6.实验结果</a></h4><p>我首先使用0.0001的学习率训练了100轮，平均每批的损失函数从7000下降至42左右。保存每轮第一批的损失函数值，观察图像发现其大概在50轮左右收敛。接着我通过保存权重的方式，在50轮后停止训练，改学习率为0.00001，平均每批的损失函数继续下降至35左右。下图是我用matplotlib.pyplot绘制的损失函数下降曲线：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Narumi-Maria/CDN/images/pasted-20.png" alt="upload successful"></p>
<p>训练收敛后，我将检测结果可视化。我采用和1中完全相同的方式，在强化学习互博中另外截图10张（存放于screen_test）文件夹中，作为测试数据输入网络中，接着采用2中介绍的方式识别落子位置，并在棋盘上显示出来（设定黑棋标黄色圈，白棋标紫色圈，结果截屏显示在screen_test_result中），其准确率高达100%。下图是其中一张测试图片与识别结果的展示：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Narumi-Maria/CDN/images/pasted-21.png" alt="upload successful"></p>

  <p> — Dec 26, 2020</p>
  


          <div class="row mt-2">
  
    <div class="eight columns">
      <p id="madewith">Made with ❤ and
        <a class="footer-link icon" href="https://hexo.io" target="_blank" style="text-decoration: none;" rel="noreferrer" aria-label="Hexo.io">
        <svg class="hexo svg-hov" width="14" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><title>Hexo.js</title><path d="M12 .007L1.57 6.056V18.05L12 23.995l10.43-6.049V5.952L12 .007zm4.798 17.105l-.939.521-.939-.521V12.94H9.08v4.172l-.94.521-.938-.521V6.89l.939-.521.939.521v4.172h5.84V6.89l.94-.521.938.521v10.222z"/></svg>
        </a>
        
        at <a href="https://en.wikipedia.org/wiki/Earth" target="_blank" rel="noreferrer">Earth</a>.</p>
        
    </div>

    <!-- Sepcial thanks to https://simpleicons.org/ for the icons -->
    <div class="four columns mb-3 posisi" >
      
      <a class="ml-0 footer-link icon" href="https://github.com/adisaktijrs" target="_blank" style="text-decoration: none" rel="noreferrer" aria-label="GitHub">
        <svg class="github svg-hov" width="18" role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>GitHub</title><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg>
      </a>
      

      
      <a class="ml-0 footer-link icon" href="https://linkedin.com/in/adisaktijrs" target="_blank" style="text-decoration: none" rel="noreferrer" aria-label="LinkedIn">
        <svg class="linkedin svg-hov" width="18" role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>LinkedIn</title><path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"/></svg>
      </a>
      

      
      <a class="ml-0 footer-link icon" href="https://twitter.com/adisaktijrs" target="_blank" style="text-decoration: none" rel="noreferrer" aria-label="Twitter">
        <svg class="twitter svg-hov" width="18" role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>Twitter</title><path d="M23.954 4.569c-.885.389-1.83.654-2.825.775 1.014-.611 1.794-1.574 2.163-2.723-.951.555-2.005.959-3.127 1.184-.896-.959-2.173-1.559-3.591-1.559-2.717 0-4.92 2.203-4.92 4.917 0 .39.045.765.127 1.124C7.691 8.094 4.066 6.13 1.64 3.161c-.427.722-.666 1.561-.666 2.475 0 1.71.87 3.213 2.188 4.096-.807-.026-1.566-.248-2.228-.616v.061c0 2.385 1.693 4.374 3.946 4.827-.413.111-.849.171-1.296.171-.314 0-.615-.03-.916-.086.631 1.953 2.445 3.377 4.604 3.417-1.68 1.319-3.809 2.105-6.102 2.105-.39 0-.779-.023-1.17-.067 2.189 1.394 4.768 2.209 7.557 2.209 9.054 0 13.999-7.496 13.999-13.986 0-.209 0-.42-.015-.63.961-.689 1.8-1.56 2.46-2.548l-.047-.02z"/></svg>
      </a>
      

      
      <a class="ml-0 footer-link icon" href="https://instagram.com/adisaktijrs" target="_blank" style="text-decoration: none" rel="noreferrer" aria-label="Instagram">
        <svg class="instagram svg-hov" width="18" role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>Instagram</title><path d="M12 0C8.74 0 8.333.015 7.053.072 5.775.132 4.905.333 4.14.63c-.789.306-1.459.717-2.126 1.384S.935 3.35.63 4.14C.333 4.905.131 5.775.072 7.053.012 8.333 0 8.74 0 12s.015 3.667.072 4.947c.06 1.277.261 2.148.558 2.913.306.788.717 1.459 1.384 2.126.667.666 1.336 1.079 2.126 1.384.766.296 1.636.499 2.913.558C8.333 23.988 8.74 24 12 24s3.667-.015 4.947-.072c1.277-.06 2.148-.262 2.913-.558.788-.306 1.459-.718 2.126-1.384.666-.667 1.079-1.335 1.384-2.126.296-.765.499-1.636.558-2.913.06-1.28.072-1.687.072-4.947s-.015-3.667-.072-4.947c-.06-1.277-.262-2.149-.558-2.913-.306-.789-.718-1.459-1.384-2.126C21.319 1.347 20.651.935 19.86.63c-.765-.297-1.636-.499-2.913-.558C15.667.012 15.26 0 12 0zm0 2.16c3.203 0 3.585.016 4.85.071 1.17.055 1.805.249 2.227.415.562.217.96.477 1.382.896.419.42.679.819.896 1.381.164.422.36 1.057.413 2.227.057 1.266.07 1.646.07 4.85s-.015 3.585-.074 4.85c-.061 1.17-.256 1.805-.421 2.227-.224.562-.479.96-.899 1.382-.419.419-.824.679-1.38.896-.42.164-1.065.36-2.235.413-1.274.057-1.649.07-4.859.07-3.211 0-3.586-.015-4.859-.074-1.171-.061-1.816-.256-2.236-.421-.569-.224-.96-.479-1.379-.899-.421-.419-.69-.824-.9-1.38-.165-.42-.359-1.065-.42-2.235-.045-1.26-.061-1.649-.061-4.844 0-3.196.016-3.586.061-4.861.061-1.17.255-1.814.42-2.234.21-.57.479-.96.9-1.381.419-.419.81-.689 1.379-.898.42-.166 1.051-.361 2.221-.421 1.275-.045 1.65-.06 4.859-.06l.045.03zm0 3.678c-3.405 0-6.162 2.76-6.162 6.162 0 3.405 2.76 6.162 6.162 6.162 3.405 0 6.162-2.76 6.162-6.162 0-3.405-2.76-6.162-6.162-6.162zM12 16c-2.21 0-4-1.79-4-4s1.79-4 4-4 4 1.79 4 4-1.79 4-4 4zm7.846-10.405c0 .795-.646 1.44-1.44 1.44-.795 0-1.44-.646-1.44-1.44 0-.794.646-1.439 1.44-1.439.793-.001 1.44.645 1.44 1.439z"/></svg>
      </a>
      

      
      <a class="ml-0 footer-link icon" href="https://stackoverflow.com/story/tobiasreithmeier" target="_blank" style="text-decoration: none" rel="noreferrer" aria-label="StackOverflow">
        <svg class="stackoverflow svh-hov" width="18" role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>Stack Overflow</title><path d="M15.725 0l-1.72 1.277 6.39 8.588 1.716-1.277L15.725 0zm-3.94 3.418l-1.369 1.644 8.225 6.85 1.369-1.644-8.225-6.85zm-3.15 4.465l-.905 1.94 9.702 4.517.904-1.94-9.701-4.517zm-1.85 4.86l-.44 2.093 10.473 2.201.44-2.092-10.473-2.203zM1.89 15.47V24h19.19v-8.53h-2.133v6.397H4.021v-6.396H1.89zm4.265 2.133v2.13h10.66v-2.13H6.154Z"/></svg>
      </a>
      

    </div>
  
</div>

        </div>
      </div>

    </div>

  </div>
  <script src="/js/nanobar.min.js"></script>
  <script>
    var options = {
      classname: 'nanobar',
      id: 'myNanobar'
    };
    var nanobar = new Nanobar(options);
    nanobar.go(30);
    nanobar.go(76);
    nanobar.go(100);
  </script>

</body>

</html>
